# Myo-Mars-Mayhem

- **Student Name:** Will Hogan
- **Student Number:** G00318460
- **College Name:** GMIT
- **Course:** Software Development
- **Module:** Gesture based UI Technology
- **Lecturer:** Damien Costello
- **Current College Year:** 4rd Year 
- **Project Title:** Myo Mars Mayhem

## Introduction

### Story...
It's the year 2034 and humans are beginning to colonise Mars. Upon receiving news from NASA back on earth, that a storm of gargantuan proportions is on a collision course with your Habitat, the future of human existence on Mars is uncertain.

However, there is hope.....

Your job is to ferry your crew out of harm's way and get to the escape pod located in a nearby location, before the Storms hits. You have a certain number of seconds to get from the Hab to the Escape pod without time running out, or coming into contact with hazardous debris or it literally is Game Over!

The World is counting on you........

### Overview
My Application for this module is a Gesture based game that uses the myo armband and animations to control/move a Ship around a canvas 
of objects until the ship has reached the Escape Pod. The myo armband uses several gestures to move up, down, 
left & right and there’s a timer that displays how long you have to get from A to B in. 
I’ve also incorporated Key Events as a separate game for those without Myo’s, so the user will be able to select either
as an option when the Application launches. 

### Purpose of the Application
The purpose of this project is to experiment with various hand arm gestures using the Myo Armband. My project incorporates a multi-faceted goal approach, for one part of my application I’ll be creating something that allows a user to wear and connect a Myo Armband, which will enable users to navigate through a canvas of objects and try and get towards a goal/exit. Another part will be to deal with collision detection, which will notify users when they have collided with another object. This involves a bit of tricky trial and error testing using various mathematical algorithms and arrangements. 


## Hardware / Software used in the Application
I’m going to be using the Myo Armband. The device will connect via Bluetooth to the user’s laptop/desktop. The user will connect their device using the Myo interface. When the game Myo Play game launches, the user will be automatically connected, before the gameplay starts. 

### Tech used
Visual Studio 2015
- C#, XAML (Menu pages and Animation page for the actual game) and theMyo Armband
-	GitHub for tracking issues, milestones, and commits. 
-	ZenHub – A GitHub integration tool, akin to Kanban board style, drag and drop tasks etc.

## Conclusions and Recommendations

### Myo Pros and Cons

|  PROS   | CONS  |
|:--------:|:-------------------------------------------:|
| Gesture control options (Fist, Wave left etc.)  | Cumbersome (Short sleeves required) |
| Gyroscope/Acc.meter (Pitch, Yaw, Roll) | Roll tipping point not always centered |
| Ability to customise your own settings | Awkward connection (Dongle --> Myo) |
| Allows multiple myo users simultaneously |	Myo freeze resulting in reset and restart |
| Can control software and hardware | No on/off button on Myo |
| Vibration Alerts |	Fingers spread gesture not always working |
| Fun to use! | No battery meter on Myo  |
| Good wrapper options (C#, C, JS, Lua…) | Slower reaction time than Keyboard |


### Conclusion
During my time working on this application I’ve learned many things from trial and error, but one of the key things that stood out are that dealing with basic Keyboard controls, is a completely different world from using Gestures to control something. This may seem obvious to some, but it’s only when you get down to the fundamental movements and controls, does this become more apparent and not so straight forward. 
For example, when you press a key you expect that it performs some key event operation, like displaying the letter k on the screen for the user. It’s also not unreasonable to expect that when they press and hold the key, that event is repeated for as long as the user has that key depressed. My point is that it’s clear-cut and simple, but that doesn’t mean that I’m suggesting that Gesture-based technology isn’t, but perhaps different and more adaptable to a user’s specific customisations. The Myo allows several different gestures, which could be specific to certain software or hardware applications. For example, the Wave-out and Wave in gestures can be used to navigate from page to page of a PowerPoint presentation or steer a robotic car from left to right. 
The real gem I think, is the inbuilt Gyroscope and Accelerometer that allow for Pitch yaw and roll movements. These movements I feel are the key ones as they represent a natural motion that mimics a specific movement like, up or down using the pitch motion. The Myo can be used to control drones, reload a gun in a first person shoot-em-up or even perform practice surgery procedures on a CGI patient object. 
Whilst this is all fantastical, it does beg the question, does the Myo have a future? In its current form, I’d say no. But technology rarely stands still for too long and if it does it’s either a remarkable piece of genius that doesn’t need to evolve or it’s outlived its current use and heading for the obsolete object heap, pardon the pun. 
What I think, is that it will become much smaller and become more responsive to fall in line with more real-time events. Its smaller form will not only be less cumbersome but become much more streamlined in physical appearance, less clunky. Can you imagine walking into your home after a day’s work, you double tap to turn on the lights of the sitting room and at the flick of a wrist (literally), you turn your TV on. This may only be the start of what the Myo can do.
To conclude, I think it’s fair to say that while one can’t ignore Gesture-based technology, that we are a long way away from emulating Tom cruise in minority report. You could call me old fashioned but it certainly feels like the keyboard won’t be going anywhere anytime soon. 
